# Deployment na Wiele Fizycznych Maszyn

## ğŸ–¥ï¸ Architektura Multi-Machine

**PrzykÅ‚adowa konfiguracja:**
- **Maszyna 1 (Coordinator + 2 Workers):** MacBook Marcin
- **Maszyna 2 (2 Workers):** Laptop kolegi / Serwer

---

## ğŸ“‹ Krok po Kroku

### **1. Przygotowanie Maszyn**

Na **KAÅ»DEJ** maszynie:

```bash
# Sklonuj repozytorium
git clone <repo-url>
cd Contemporary-Data-Processing-Systems-Project

# Zainstaluj zaleÅ¼noÅ›ci
pip3 install -r requirements.txt

# Pobierz dane (opcjonalnie - moÅ¼e byÄ‡ tylko na coordinator)
cd data/
wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet
cd ..
```

---

### **2. Poznaj IP Adres KaÅ¼dej Maszyny**

**Na kaÅ¼dej maszynie:**

```bash
# macOS/Linux
ifconfig | grep "inet " | grep -v 127.0.0.1

# Lub proÅ›ciej (macOS)
ipconfig getifaddr en0  # WiFi
ipconfig getifaddr en1  # Ethernet

# PrzykÅ‚adowe wyniki:
# Maszyna 1: 192.168.1.10
# Maszyna 2: 192.168.1.20
```

**WAÅ»NE:** Wszystkie maszyny muszÄ… byÄ‡ w tej samej sieci (WiFi/LAN)!

---

### **3. Edytuj config.yaml**

**Na KAÅ»DEJ maszynie edytuj ten sam plik:**

```yaml
cluster:
  coordinator:
    host: "192.168.1.10"  # IP Maszyny 1 (tam gdzie bÄ™dzie coordinator)
    port: 5000
    
  workers:
    # Workers na Maszynie 1
    - id: "worker-1"
      host: "192.168.1.10"  # IP Maszyny 1
      port: 5001
      data_dir: "./data/worker1"
      
    - id: "worker-2"
      host: "192.168.1.10"  # IP Maszyny 1
      port: 5002
      data_dir: "./data/worker2"
      
    # Workers na Maszynie 2
    - id: "worker-3"
      host: "192.168.1.20"  # IP Maszyny 2
      port: 5001
      data_dir: "./data/worker3"
      
    - id: "worker-4"
      host: "192.168.1.20"  # IP Maszyny 2
      port: 5002
      data_dir: "./data/worker4"

dataset:
  path: "./data/yellow_tripdata_2024-01.parquet"
  max_records: 50000  # Dla testÃ³w
```

**ğŸ’¡ Tip:** MoÅ¼esz mieÄ‡ rÃ³Å¼ne porty na rÃ³Å¼nych maszynach (oba 5001) albo rÃ³Å¼ne na tej samej (5001, 5002).

---

### **4. Uruchom Workers**

**Na Maszynie 1 (192.168.1.10):**

Terminal 1:
```bash
python3 main.py worker worker-1 --host 0.0.0.0 --port 5001
```

Terminal 2:
```bash
python3 main.py worker worker-2 --host 0.0.0.0 --port 5002
```

**Na Maszynie 2 (192.168.1.20):**

Terminal 1:
```bash
python3 main.py worker worker-3 --host 0.0.0.0 --port 5001
```

Terminal 2:
```bash
python3 main.py worker worker-4 --host 0.0.0.0 --port 5002
```

**âš ï¸ WAÅ»NE:** UÅ¼yj `--host 0.0.0.0` Å¼eby worker sÅ‚uchaÅ‚ na wszystkich interfejsach (nie tylko localhost)!

---

### **5. Uruchom Coordinator**

**Na Maszynie 1** (tam gdzie sÄ… dane):

```bash
python3 main.py coordinator --task 1
```

Coordinator:
- âœ… Sprawdzi czy wszystkie 4 workery sÄ… dostÄ™pne (health check)
- âœ… ZaÅ‚aduje dane z lokalnego pliku Parquet
- âœ… Podzieli dane miÄ™dzy 4 workery
- âœ… Uruchomi analizÄ™
- âœ… Zbierze wyniki

---

## ğŸ”¥ Firewall / Porty

**macOS:**

```bash
# SprawdÅº czy firewall jest wÅ‚Ä…czony
sudo /usr/libexec/ApplicationFirewall/socketfilterfw --getglobalstate

# JeÅ›li potrzeba, pozwÃ³l Python na poÅ‚Ä…czenia przychodzÄ…ce
# (System wyÅ›wietli dialog przy pierwszym uruchomieniu)
```

**Linux:**

```bash
# OtwÃ³rz porty 5001-5002
sudo ufw allow 5001
sudo ufw allow 5002

# Lub wyÅ‚Ä…cz firewall tymczasowo (tylko do testÃ³w!)
sudo ufw disable
```

**Windows:**

```powershell
# Dodaj reguÅ‚Ä™ firewall
netsh advfirewall firewall add rule name="MapReduce Workers" dir=in action=allow protocol=TCP localport=5001-5002
```

---

## ğŸ§ª Test PoÅ‚Ä…czenia

**Z Maszyny 1, przetestuj poÅ‚Ä…czenie do Maszyny 2:**

```bash
# Test czy worker-3 odpowiada
curl http://192.168.1.20:5001/health

# Powinno zwrÃ³ciÄ‡:
# {"status":"healthy","worker_id":"worker-3"}
```

**Z Maszyny 2, przetestuj MaszynÄ™ 1:**

```bash
curl http://192.168.1.10:5001/health
```

JeÅ›li dostajesz `Connection refused` lub timeout:
- âœ… SprawdÅº czy worker dziaÅ‚a (`ps aux | grep python`)
- âœ… SprawdÅº firewall
- âœ… SprawdÅº czy IP sÄ… poprawne
- âœ… SprawdÅº czy jesteÅ›cie w tej samej sieci

---

## ğŸ“Š PrzykÅ‚adowy Output

```
Worker http://192.168.1.10:5001 is healthy
Worker http://192.168.1.10:5002 is healthy
Worker http://192.168.1.20:5001 is healthy
Worker http://192.168.1.20:5002 is healthy

Loading NYC Taxi data from ./data/yellow_tripdata_2024-01.parquet
Loaded 50,000 records from Parquet file

Executing map phase...
Map task 1/4 completed
Map task 2/4 completed
Map task 3/4 completed
Map task 4/4 completed

Executing reduce phase...
Reduce task 1/4 completed
...
```

---

## ğŸš€ Alternatywa: Screen/tmux

JeÅ›li masz SSH do drugiej maszyny, moÅ¼esz uruchomiÄ‡ wszystko z jednej:

**Na Maszynie 1:**

```bash
# Uruchom lokalne workery
python3 main.py worker worker-1 --host 0.0.0.0 --port 5001 &
python3 main.py worker worker-2 --host 0.0.0.0 --port 5002 &

# SSH do Maszyny 2 i uruchom workery
ssh user@192.168.1.20 "cd ~/Contemporary-Data-Processing-Systems-Project && python3 main.py worker worker-3 --host 0.0.0.0 --port 5001" &
ssh user@192.168.1.20 "cd ~/Contemporary-Data-Processing-Systems-Project && python3 main.py worker worker-4 --host 0.0.0.0 --port 5002" &

# Odczekaj 3 sekundy
sleep 3

# Uruchom coordinator
python3 main.py coordinator --task 1
```

---

## ğŸ¯ NajÅ‚atwiejsza Konfiguracja (2 laptopy w jednym WiFi)

**Laptop 1 (TwÃ³j MacBook):**
- IP: 192.168.1.10
- Worker-1 na porcie 5001
- Worker-2 na porcie 5002
- Coordinator

**Laptop 2 (Kolega):**
- IP: 192.168.1.20
- Worker-3 na porcie 5001
- Worker-4 na porcie 5002

**config.yaml** (ten sam na obu):
```yaml
workers:
  - id: "worker-1"
    host: "192.168.1.10"
    port: 5001
  - id: "worker-2"
    host: "192.168.1.10"
    port: 5002
  - id: "worker-3"
    host: "192.168.1.20"
    port: 5001
  - id: "worker-4"
    host: "192.168.1.20"
    port: 5002
```

---

## âš¡ Demo na Prezentacji

**Efektowne:**

1. PokaÅ¼cie 2 laptopy obok siebie
2. Na kaÅ¼dym terminal z workerami
3. Logi pokazujÄ… wymianÄ™ danych miÄ™dzy maszynami
4. Na koÅ„cu wyniki agregowane z 2 lokalizacji fizycznych

**Mniej efektowne ale dziaÅ‚a:**

Wszystko na localhost (jak teraz) - teÅ¼ jest OK dla prezentacji.

---

## ğŸ› Troubleshooting

### Workers siÄ™ nie widzÄ…

```bash
# SprawdÅº routing
ping 192.168.1.20

# SprawdÅº czy port jest otwarty
nc -zv 192.168.1.20 5001

# Zobacz logi workerÃ³w
# Powinny pokazywaÄ‡ requesty od coordinatora
```

### "Connection refused"

- Worker nie dziaÅ‚a lub nie nasÅ‚uchuje na 0.0.0.0
- Firewall blokuje
- ZÅ‚y port/IP w config.yaml

### "Map task failed"

- Prawdopodobnie worker padÅ‚ podczas przetwarzania
- SprawdÅº logi workerÃ³w
- MoÅ¼e za maÅ‚o RAM (3M rekordÃ³w to ~2GB pamiÄ™ci)

---

## ğŸ’¡ Pro Tips

1. **Sync config.yaml**: UÅ¼yj `git` Å¼eby mieÄ‡ ten sam config na obu maszynach
2. **Symlink do danych**: Tylko jedna maszyna (coordinator) potrzebuje pliku Parquet
3. **Monitoring**: Uruchom `htop` na workerach Å¼eby widzieÄ‡ uÅ¼ycie CPU/RAM
4. **Logi**: Dodaj `> worker.log 2>&1` Å¼eby zapisywaÄ‡ logi
5. **Testuj lokalnie pierwszy**: Upewnij siÄ™ Å¼e dziaÅ‚a na localhost przed multi-machine

---

## ğŸ“ Checklist Przed PrezentacjÄ…

- [ ] Config.yaml ma prawidÅ‚owe IP
- [ ] Workery startujÄ… na 0.0.0.0 (nie localhost)
- [ ] Health check przechodzi dla wszystkich workerÃ³w
- [ ] Firewall przepuszcza porty 5001-5002
- [ ] Obie maszyny w tej samej sieci
- [ ] Dane Parquet sÄ… na maszynie z coordinator
- [ ] Test run dziaÅ‚a

Powodzenia! ğŸš€
